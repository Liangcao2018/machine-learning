{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多维异常检测算法仿真（算法实践）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、数据采集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 读取 CPU\\磁盘读\\磁盘写\\网络出口\\网络入口\\内存等监控指标，数据来源：广西科大数据（2017.1-2017.2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('figure', figsize=(15, 6))\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vCpuUsage = pd.read_excel('../ECUST data/Guangxi university data 20170228/CPU_20170228171221.xlsx',converters={u'时间':parse})\n",
    "vDiskRead = pd.read_excel('../ECUST data/Guangxi university data 20170228/DiskRead_20170228171404.xlsx',converters={u'时间':parse})\n",
    "vDiskWrite = pd.read_excel('../ECUST data/Guangxi university data 20170228/DiskWrite_20170228171432.xlsx',converters={u'时间':parse})\n",
    "vNwEgress = pd.read_excel('../ECUST data/Guangxi university data 20170228/NwEgress_20170228171526.xlsx',converters={u'时间':parse})\n",
    "vNwIngress = pd.read_excel('../ECUST data/Guangxi university data 20170228/NwIngress_20170228171623.xlsx',converters={u'时间':parse})\n",
    "vMemUsage = pd.read_excel('../ECUST data/Guangxi university data 20170228/Memory_20170228171333.xlsx',converters={u'时间':parse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "\n",
    "### 修改index和columns\n",
    "for var in (vCpuUsage,vDiskRead,vDiskWrite,vNwEgress,vNwIngress,vMemUsage):\n",
    "    var.rename(columns={u'资源':'vres',u'类型':'vtype',u'时间':'vtime',u'最大值':'vmax',u'最小值':'vmin',u'平均值':'vavg',u'单位':'vunit'},\n",
    "               inplace = True)\n",
    "    if 'vtime' in var.columns.values:\n",
    "        var.set_index('vtime',inplace=True) \n",
    "\n",
    "### 初步探索时间序列数据,形成待分析多维数据矩阵X\n",
    "X = pd.concat([vCpuUsage.to_period('Min').vavg,\n",
    "               vDiskRead.to_period('Min').vavg,\n",
    "               vDiskWrite.to_period('Min').vavg,\n",
    "               vNwEgress.to_period('Min').vavg,\n",
    "               vNwIngress.to_period('Min').vavg,\n",
    "               vMemUsage.to_period('Min').vavg],axis=1,keys=['vCpuUsage','vDiskRead','vDiskWrite','vNwEgress','vNwIngress','vMemUsage'])\n",
    "\n",
    "### 对缺失数据进行插值处理\n",
    "#设定初始值后，对NaN进行线性插值\n",
    "X.ix[0,X.ix[0].isnull()]=0\n",
    "X.interpolate(method='time',inplace=True)\n",
    "\n",
    "### 对CPU 0值数据进行填充\n",
    "for i in range(1,len(X.vCpuUsage)):\n",
    "    if X.vCpuUsage[i]==0:\n",
    "        X.vCpuUsage[i] = X.vCpuUsage[i-1] \n",
    "\n",
    "#保留原始值\n",
    "X_Original=X\n",
    "\n",
    "### 无量纲化\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_MinMaxScaler=MinMaxScaler().fit(X_Original)\n",
    "X = DataFrame(X_MinMaxScaler.transform(X_Original),index=X_Original.index,columns=X_Original.columns)\n",
    "\n",
    "#区间缩放后再将均值0化，这主要是由于部分算法会自行对均值进行处理（比如pca的transform），为避免算法理解上的干扰，调整均值为0\n",
    "X_mean=X.mean()\n",
    "X = X-X_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、获取PCA残差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_pca=PCA().fit(X)\n",
    "X_pca_T=X_pca.transform(X)\n",
    "\n",
    "#指定主成分的方差和所占的最小比例阈值为0.85\n",
    "X_pca_n=np.where(np.cumsum(X_pca.explained_variance_ratio_)>0.85)[0][0]+1 #得到index后再+1，表示个数\n",
    "X_pca_recover=DataFrame(np.dot(X_pca_T[:,:X_pca_n],X_pca.components_[:X_pca_n,:]),index=X.index,columns=X.columns)\n",
    "X_pca_residual=X-X_pca_recover\n",
    "\n",
    "#获取残差能量占比0.85的主成分个数\n",
    "X_pca_residual_n=np.where(np.cumsum(X_pca.explained_variance_ratio_[X_pca_n:])/np.sum(X_pca.explained_variance_ratio_[X_pca_n:])>0.85)[0][0]+1 #得到index后再+1，表示个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 考虑计算效率，这里简化了残差主成分个数的计算方式，避免再次调用PCA算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、基于残差空间的ICA异常检测算法应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomal periods detected by T2 metric are: \n",
      "(Period('2017-01-12 16:20', 'T'), Period('2017-01-12 16:26', 'T'))\n",
      "(Period('2017-01-15 11:25', 'T'), Period('2017-01-15 11:31', 'T'))\n",
      "(Period('2017-01-16 04:46', 'T'), Period('2017-01-16 04:53', 'T'))\n",
      "(Period('2017-01-16 10:10', 'T'), Period('2017-01-16 10:35', 'T'))\n",
      "(Period('2017-01-18 09:50', 'T'), Period('2017-01-18 10:08', 'T'))\n",
      "(Period('2017-01-18 10:46', 'T'), Period('2017-01-18 10:46', 'T'))\n",
      "(Period('2017-01-20 12:37', 'T'), Period('2017-01-20 12:53', 'T'))\n",
      "(Period('2017-01-21 10:41', 'T'), Period('2017-01-21 10:45', 'T'))\n",
      "(Period('2017-01-21 15:23', 'T'), Period('2017-01-21 15:42', 'T'))\n",
      "(Period('2017-02-20 10:26', 'T'), Period('2017-02-20 10:32', 'T'))\n",
      "(Period('2017-02-20 10:56', 'T'), Period('2017-02-20 12:18', 'T'))\n",
      "(Period('2017-02-20 12:39', 'T'), Period('2017-02-20 12:43', 'T'))\n",
      "(Period('2017-02-20 13:31', 'T'), Period('2017-02-20 13:40', 'T'))\n",
      "(Period('2017-02-20 15:24', 'T'), Period('2017-02-20 15:24', 'T'))\n",
      "(Period('2017-02-20 17:41', 'T'), Period('2017-02-20 17:52', 'T'))\n",
      "(Period('2017-02-20 19:15', 'T'), Period('2017-02-20 19:15', 'T'))\n",
      "(Period('2017-02-22 10:22', 'T'), Period('2017-02-22 10:25', 'T'))\n",
      "(Period('2017-02-24 10:32', 'T'), Period('2017-02-24 10:32', 'T'))\n",
      "(Period('2017-02-25 08:07', 'T'), Period('2017-02-25 08:07', 'T'))\n",
      "(Period('2017-02-25 08:39', 'T'), Period('2017-02-25 08:41', 'T'))\n",
      "(Period('2017-02-25 09:21', 'T'), Period('2017-02-25 09:23', 'T'))\n",
      "(Period('2017-02-25 11:40', 'T'), Period('2017-02-25 11:40', 'T'))\n",
      "anomal periods detected by SPE metric are: \n",
      "(Period('2017-01-12 16:21', 'T'), Period('2017-01-12 16:25', 'T'))\n",
      "(Period('2017-01-15 11:22', 'T'), Period('2017-01-15 11:34', 'T'))\n",
      "(Period('2017-01-16 04:49', 'T'), Period('2017-01-16 04:51', 'T'))\n",
      "(Period('2017-01-16 10:13', 'T'), Period('2017-01-16 10:36', 'T'))\n",
      "(Period('2017-02-14 16:18', 'T'), Period('2017-02-14 16:25', 'T'))\n",
      "(Period('2017-02-20 11:23', 'T'), Period('2017-02-20 11:25', 'T'))\n",
      "(Period('2017-02-20 11:41', 'T'), Period('2017-02-20 12:14', 'T'))\n",
      "(Period('2017-02-20 17:45', 'T'), Period('2017-02-20 17:49', 'T'))\n",
      "(Period('2017-02-20 18:11', 'T'), Period('2017-02-20 19:30', 'T'))\n",
      "(Period('2017-02-20 20:42', 'T'), Period('2017-02-20 21:11', 'T'))\n",
      "(Period('2017-02-20 21:50', 'T'), Period('2017-02-20 22:04', 'T'))\n",
      "(Period('2017-02-20 22:21', 'T'), Period('2017-02-20 22:54', 'T'))\n",
      "(Period('2017-02-25 09:01', 'T'), Period('2017-02-25 09:01', 'T'))\n",
      "算法用时： 3.850679636001587 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "from scipy import stats\n",
    "\n",
    "def my_kde_bandwidth(obj, fac=1./2):\n",
    "    \"\"\"We use Scott's Rule, multiplied by a constant factor.\"\"\"\n",
    "    return np.power(obj.n, -1./(obj.d+4)) * fac\n",
    "\n",
    "def get_threshold_of_scipy_kde(kde,start,step=1,confidence=0.997):\n",
    "    \"\"\"get threshold by confidence\"\"\"\n",
    "    i = start\n",
    "    cumsum = kde.integrate_box_1d(-np.inf, start)\n",
    "    while True:\n",
    "        if cumsum >= confidence:\n",
    "            break\n",
    "        cumsum = cumsum + kde.integrate_box_1d(i, i+step)\n",
    "        i = i + step        \n",
    "    return i\n",
    "\n",
    "#确定独立成分\n",
    "n=X_pca_residual_n+1\n",
    "\n",
    "#提取异常成分\n",
    "X_pca_residual_ica=FastICA(n_components=n).fit(X_pca_residual)\n",
    "X_pca_residual_S_=X_pca_residual_ica.transform(X_pca_residual)\n",
    "X_pca_residual_ica_recover=DataFrame(np.dot(X_pca_residual_S_,X_pca_residual_ica.mixing_.T)+X_pca_residual_ica.mean_,\n",
    "                                index=X_pca_residual.index,columns=X_pca_residual.columns)\n",
    "\n",
    "#计算T2统计量\n",
    "X_pca_residual_ica_T2=Series(np.sum(X_pca_residual_S_**2,axis=1),index=X_pca_residual.index)\n",
    "#计算SPE统计量\n",
    "X_pca_residual_ica_SPE=Series(np.sum((X_pca_residual-X_pca_residual_ica_recover)**2,axis=1),index=X_pca_residual.index)\n",
    "\n",
    "# 通过概率密度函数求解概率时的累加步长设置(中位数与最大值距离100步)\n",
    "X_pca_residual_ica_T2_pdf_step=(X_pca_residual_ica_T2.max()-X_pca_residual_ica_T2.median())/100\n",
    "X_pca_residual_ica_SPE_pdf_step=(X_pca_residual_ica_SPE.max()-X_pca_residual_ica_SPE.median())/100\n",
    "\n",
    "#kde及阈值估计\n",
    "X_pca_residual_ica_T2_scipy_kde=stats.gaussian_kde(X_pca_residual_ica_T2, bw_method=my_kde_bandwidth)\n",
    "X_pca_residual_ica_SPE_scipy_kde=stats.gaussian_kde(X_pca_residual_ica_SPE, bw_method=my_kde_bandwidth)\n",
    "X_pca_residual_ica_T2_threshold=get_threshold_of_scipy_kde(X_pca_residual_ica_T2_scipy_kde,X_pca_residual_ica_T2.min(),step=X_pca_residual_ica_T2_pdf_step,confidence=0.997)\n",
    "X_pca_residual_ica_SPE_threshold=get_threshold_of_scipy_kde(X_pca_residual_ica_SPE_scipy_kde,X_pca_residual_ica_SPE.min(),step=X_pca_residual_ica_SPE_pdf_step,confidence=0.997)\n",
    "\n",
    "#输出异常时间段\n",
    "X_pca_residual_ica_T2_anomaly=X_pca_residual_ica_T2[X_pca_residual_ica_T2>X_pca_residual_ica_T2_threshold].index\n",
    "if len(X_pca_residual_ica_T2_anomaly)!=0:\n",
    "    indice=pd.Series([True]+list(np.diff(X_pca_residual_ica_T2_anomaly)>10))\n",
    "    X_pca_residual_ica_T2_anomaly_start=X_pca_residual_ica_T2_anomaly[indice].tolist()\n",
    "    X_pca_residual_ica_T2_anomaly_end=X_pca_residual_ica_T2_anomaly[indice.shift(-1).fillna(False)].tolist()\n",
    "    X_pca_residual_ica_T2_anomaly_end.append(X_pca_residual_ica_T2_anomaly[-1])\n",
    "    print('anomal periods detected by T2 metric are: ')\n",
    "    for each in zip(X_pca_residual_ica_T2_anomaly_start,X_pca_residual_ica_T2_anomaly_end):    \n",
    "        print(each)\n",
    "else:\n",
    "    print('there\\'s no anomal periods detected by T2 metric ')\n",
    "    \n",
    "X_pca_residual_ica_SPE_anomaly=X_pca_residual_ica_SPE[X_pca_residual_ica_SPE>X_pca_residual_ica_SPE_threshold].index\n",
    "if len(X_pca_residual_ica_SPE_anomaly)!=0:\n",
    "    indice=pd.Series([True]+list(np.diff(X_pca_residual_ica_SPE_anomaly)>10))\n",
    "    X_pca_residual_ica_SPE_anomaly_start=X_pca_residual_ica_SPE_anomaly[indice].tolist()\n",
    "    X_pca_residual_ica_SPE_anomaly_end=X_pca_residual_ica_SPE_anomaly[indice.shift(-1).fillna(False)].tolist()\n",
    "    X_pca_residual_ica_SPE_anomaly_end.append(X_pca_residual_ica_SPE_anomaly[-1])\n",
    "    print('anomal periods detected by SPE metric are: ')\n",
    "    for each in zip(X_pca_residual_ica_SPE_anomaly_start,X_pca_residual_ica_SPE_anomaly_end):\n",
    "        print(each)\n",
    "else:\n",
    "    print('there\\'s no anomal periods detected by SPE metric ')\n",
    "        \n",
    "print('算法用时：',time.time()-start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5、在线应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1、数据采集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX=X_Original.ix['2017-01-18 08:50':'2017-01-18 10:50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2、测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomal periods detected by T2 metric are: \n",
      "(Period('2017-01-18 09:50', 'T'), Period('2017-01-18 10:08', 'T'))\n",
      "(Period('2017-01-18 10:46', 'T'), Period('2017-01-18 10:46', 'T'))\n",
      "there's no anomal periods detected by SPE metric \n",
      "算法用时： 0.011068344116210938 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "#数据预处理\n",
    "testX = DataFrame(X_MinMaxScaler.transform(testX),index=testX.index,columns=testX.columns)-X_mean\n",
    "\n",
    "#获取残差空间\n",
    "testX_pca_recover=DataFrame(np.dot(np.dot(testX,X_pca.components_[:X_pca_n,:].T),X_pca.components_[:X_pca_n,:]),index=testX.index,columns=testX.columns)\n",
    "testX_pca_residual=testX-testX_pca_recover\n",
    "\n",
    "#提取异常成分\n",
    "testX_pca_residual_S_=X_pca_residual_ica.transform(testX_pca_residual)\n",
    "testX_pca_residual_ica_recover=DataFrame(np.dot(testX_pca_residual_S_,X_pca_residual_ica.mixing_.T)+X_pca_residual_ica.mean_,\n",
    "                                index=testX_pca_residual.index,columns=testX_pca_residual.columns)\n",
    "\n",
    "#计算T2统计量\n",
    "testX_pca_residual_ica_T2=Series(np.sum(testX_pca_residual_S_**2,axis=1),index=testX_pca_residual.index)\n",
    "#计算SPE统计量\n",
    "testX_pca_residual_ica_SPE=Series(np.sum((testX_pca_residual-testX_pca_residual_ica_recover)**2,axis=1),index=testX_pca_residual.index)\n",
    "\n",
    "#输出异常时间段\n",
    "testX_pca_residual_ica_T2_anomaly=testX_pca_residual_ica_T2[testX_pca_residual_ica_T2>X_pca_residual_ica_T2_threshold].index\n",
    "if len(testX_pca_residual_ica_T2_anomaly)!=0:\n",
    "    indice=pd.Series([True]+list(np.diff(testX_pca_residual_ica_T2_anomaly)>10))\n",
    "    testX_pca_residual_ica_T2_anomaly_start=testX_pca_residual_ica_T2_anomaly[indice].tolist()\n",
    "    testX_pca_residual_ica_T2_anomaly_end=testX_pca_residual_ica_T2_anomaly[indice.shift(-1).fillna(False)].tolist()\n",
    "    testX_pca_residual_ica_T2_anomaly_end.append(testX_pca_residual_ica_T2_anomaly[-1])\n",
    "    print('anomal periods detected by T2 metric are: ')\n",
    "    for each in zip(testX_pca_residual_ica_T2_anomaly_start,testX_pca_residual_ica_T2_anomaly_end):    \n",
    "        print(each)\n",
    "else:\n",
    "    print('there\\'s no anomal periods detected by T2 metric ')\n",
    "    \n",
    "testX_pca_residual_ica_SPE_anomaly=testX_pca_residual_ica_SPE[testX_pca_residual_ica_SPE>X_pca_residual_ica_SPE_threshold].index\n",
    "if len(testX_pca_residual_ica_SPE_anomaly)!=0:\n",
    "    indice=pd.Series([True]+list(np.diff(testX_pca_residual_ica_SPE_anomaly)>10))\n",
    "    testX_pca_residual_ica_SPE_anomaly_start=testX_pca_residual_ica_SPE_anomaly[indice].tolist()\n",
    "    testX_pca_residual_ica_SPE_anomaly_end=testX_pca_residual_ica_SPE_anomaly[indice.shift(-1).fillna(False)].tolist()\n",
    "    testX_pca_residual_ica_SPE_anomaly_end.append(testX_pca_residual_ica_SPE_anomaly[-1])\n",
    "    print('anomal periods detected by SPE metric are: ')\n",
    "    for each in zip(testX_pca_residual_ica_SPE_anomaly_start,testX_pca_residual_ica_SPE_anomaly_end):\n",
    "        print(each)\n",
    "else:\n",
    "    print('there\\'s no anomal periods detected by SPE metric ')\n",
    "    \n",
    "print('算法用时：',time.time()-start,'s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
